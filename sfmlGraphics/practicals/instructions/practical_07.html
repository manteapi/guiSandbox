<!DOCTYPE html>
<html lang="en">
  <head>
    <title> Practical 7: Texturing</title>

    <!-- metadata -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="ENSIMAG Computer Graphics 3D Tutorials.">
    <meta name="author" content="Pierre-Luc Manteaux">
    <meta name="author" content="Thomas Delame">

    <!-- 
#############
# libraries #
#############
bootstrap for style/appearance
jquery for interactions
mathjax for mathematic symbols (basically latex in html) 
highlight for code highlighting -->
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-1.11.2.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['\\(', '\\)']]
        }
      });
    </script>
    <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="./javascript/mathjax_local.js"></script>
    <!-- Highlight package for code highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/styles/idea.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!--
####################
# linked resources #
#################### -->
    <link href="./css/tutorial.css" rel="stylesheet">
  </head>
  <body data-spy="scroll" data-target="#page-nav" class="tutorial">
    <header> 
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1">
              <span class="sr-only"> Toggle navigation </span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="../index.html">3DCG Practicals</a>
          </div>
          <div class="collapse navbar-collapse" id="navbar-collapse-1">
            <ul class="nav navbar-nav">
              <li>
                <button type="button" data-toggle="dropdown"> Practicals <span class="caret"></span></button>
                <ul class="dropdown-menu">
                  <li><a href="./practical_01.html">Pratical 1 - A quick &amp; dirty introduction to OpenGL</a></li>
                  <li><a href="./practical_02.html">Pratical 2 - 3D primitive modeling</a></li>
                  <li><a href="./practical_03.html">Pratical 3 - Hierarchical modeling </a></li>
                  <li><a href="./practical_04.html">Pratical 4 - Procedural animation </a></li>
                  <li><a href="./practical_05.html">Pratical 5 - Physics-based animation </a></li>
                  <li><a href="./practical_06.html">Pratical 6 - Local illumination </a></li>
                  <li><a href="./practical_07.html">Pratical 7 - Texturing </a></li>
                </ul>
              <li><a href="./project.html"> Project</a></li>
              <li><a href="./../api_doc/index.html"> Documentation </a></li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <div class="header">
      <div class="container">
        <span class="title"> 3D Computer Graphics Practicals </span>
        <p> 
          Introduction to Computer Graphics with OpenGL 4 and C++
        </p>
      </div>
    </div>   

    <div class="container">
      <div class="row">
        <div class="col-md-10" role="main">

          <header><h1> Practical 7 - Texturing</h1></header>

          <p> You might have heard about texturing as a technique that could increase the realism of a rendering, by mapping parts of an image onto triangles.
            In fact, texturing is a wider concept: it is the sampling of a function \(f\) at a real valued position \(p\). The coordinates of \(p\) are all in the range \(\left[0,1\right]\).
            The function \(f\) is known at regularly spaced discrete positions, i.e. on a 1-, 2-, or 3-dimensional grid, depending on the case. The values of \(f\) on this grid is referred to
            as the <strong>texture</strong> and the real valued position \(p\) is known as the <strong>texture coordinate</strong>.
          </p>

          <p> In this practical, all textures will be 2D RGBA images, i.e. functions that associate a RGBA color to a 2-dimensional coordinate. The texture coordinates are generally written \((u,v)\) in that case. Such coordinates are given for each vertex of a triangle (see the image below to see where is the coordinates origin in the <strong>OpenGL convention</strong>). Texture coordinates are vertex attributes, thus fragments will have interpolated vertex coordinates. The texture will be then <strong>sampled</strong> at those coordinates, giving <strong>texels</strong> (texture elements) and a fragment will use its texel to compute its final color.         
          </p>

          <!-- <img id="texture_example" src="./images/07_uv_coordinates.png" class="tutorial-img img-rounded img-responsive" style="style= max-width: 100%" alt="2D texture coordinates"> -->
          <img id="texture_example" src="./images/texture_coords.png" class="tutorial-img img-rounded img-responsive" style="style= max-width: 100%" alt="2D texture coordinates">


          <p> You will not code much in this practical. We have chosen to let you observe the code and experiment the effects of different option values, in order to understand both the mecanism and the
            possibilities of texturing. When you got the concept, you will then add texturing to the renderables of your project. </p>

          <button type="button" class="btn btn-info" data-toggle="collapse" data-target="#texture_nD">Texture of other dimensions</button>
          <div id="texture_nD" class="collapse">
            <div class="well">
              <p> 
                Textures can have other dimensions and store different values. For example:
              </p>
              <ul>
                <li>a two dimensional texture storing real values that represent the height of the ground relatively to a known maximum height. The texture is what we call an <strong>elevation map</strong>
                </li>
                <li>a one dimensional texture storing RGB colors. This is typically used as a lookup table to associate a color to a scalar value, in order to visualise 1-D values defined on a surface. </li>
                <li>
                  a three dimensional texture storing real values in order to visualize medical images (CT scan, IRM, ...).
                </li>
              </ul>
            </div>
          </div>



          <button type="button" class="btn btn-info" data-toggle="collapse" data-target="#texture_create_coords">Defining texture coordinates</button>
          <div id="texture_create_coords" class="collapse">
            <div class="well">
              <p> 
                The definition of texture coordinates for 2D surfaces may be a <b>tough</b> problem. The surface needs to be embedded in a two dimensional space. Even for 3D meshes, some methods exists but they are beyond the scope of this course. Thus, for the project, try to keep things simple or find a mesh with existing texture coordinates relatively to an existing image (see <a href="#bunny_uv_map">exercice 1</a>).
              </p>
            </div>
          </div>

          <h2 id="reminder">1. Reminder: How to compile from scratch</h2>

          <pre><code class="bash">#Switch to a C++11 compiler (at ENSIMAG only)
source gcc493.sh

#Compile external libraries (if new lib has been added)
cd extlib/
make clean_all
make

#Compile project
cd ../
rm -rf build/
mkdir build/
cd build/
cmake ..
make -j 8</code></pre>

          <h2 id="additional">2. Additional files</h2>
          <ul>
            <li>Download the source of the practical <a href="./../resources/practical7.zip"> here </a>.</li>
            <li>Unzip it.</li>
            <li>Copy the <samp>extlib</samp> directory from you previous practical in this new directory called <samp>practical7</samp>.
              Alternatively, you can simply create a symbolic link to the existing libraries. <br>
              For example: <samp>cd practical7</samp> then <samp>ln -s ../practical2/extlib</samp></li>
            <li>Compile your project by following the <a href="#reminder">previous instructions</a>.</li>
          </ul>

          <h2 id="provided_code">3. About the provided code</h2>
          <p> 
            The provided code illustrates different basic texturing techniques:
          </p>
          <ul>
            <li>
              CPU code is encapsulated into C++ classes that are gathered in a <samp>texturing</samp> subdirectory.
            </li>
            <li>
              GPU code is gathered in the <samp>shaders</samp> subdirectory.
            </li>
          </ul>

          <p> We will now give more details about important parts of the provided code.</p>

          <h3> 3.1 CPU code for texturing </h3>

          <h4> Set up a texture </h4>
          <p> Like any memory place in OpenGL, a texture is managed thanks to an ID. This ID is first generated then bound to a binding point before transferring the data to the GPU. Apart from the texture options defined by the <code>glTexParameteri</code> function (studied in the following exercises), this operation is very similar to what you are now used to do on vertex buffers. After this operation is done (only once), the texture can be used for rendering.</p>
          <button type="button" class="btn btn-info" data-toggle="collapse" data-target="#setup_a_texture"> C++ code to setup a texture</button>
          <div id="setup_a_texture" class="collapse">
            <pre><code class="cpp">// Create a new texture id, then bind it
glGenTextures(1, &m_texId);
glBindTexture(GL_TEXTURE_2D, m_texId);

// Texture options
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);

// Load an image (here using the sfml library)
sf::Image image;
image.loadFromFile(filename);
// sfml inverts the v axis... 
// Hence, flip it to put the image in OpenGL convention: lower left corner is (0,0)
image.flipVertically(); 

// Transfer the image to the texture on the GPU
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA32F, image.getSize().x, image.getSize().y, 0, GL_RGBA, GL_UNSIGNED_BYTE, (const GLvoid*)image.getPixelsPtr());

// Release the texture id
glBindTexture(GL_TEXTURE_2D, 0);</code></pre>
          </div>

          <h4> Define texture coordinates </h4>
          <p> As we saw in the introduction, texture coordinates are vertex attributes. As such, they are loaded in a vertex buffer. This is not something new, but you should remember to define and load the texture coordinate attribute.</p>
          <button type="button" class="btn btn-info" data-toggle="collapse" data-target="#load_texture_coordinates"> C++ code to load texture coordinates</button>
          <div id="load_texture_coordinates" class="collapse">
            <pre><code class="cpp">// Example with a single triangle
m_positions.push_back(glm::vec3(-1.0, 0.0, 0.0));
m_positions.push_back(glm::vec3( 1.0, 0.0, 0.0));
m_positions.push_back(glm::vec3( 0.0, 1.0, 0.0));

m_texCoords.push_back(glm::vec2(0.2, 0.2)); //close to the texture's lower left corner 
m_texCoords.push_back(glm::vec2(1.0, 0.0)); //lower right corner of the texture
m_texCoords.push_back(glm::vec2(0.5, 1.0)); //middle of the top line of the texture

// Generate buffers and send data to the GPU, as usual
...  
glGenBuffers(1, &m_tBuffer);
glBindBuffer(GL_ARRAY_BUFFER, m_tBuffer);
glBufferData(GL_ARRAY_BUFFER, m_texCoords.size()*sizeof(glm::vec2), m_texCoords.data(), GL_STATIC_DRAW);</code></pre>
          </div>

          <h4> Using the texture in the shader program </h4>
          <p>This step is actually different than for other type of vertex attributes. The texture should first be bound to a binding point the shader program can use. This binding point is named a <strong>texture unit</strong>, and in this case we will use <code> GL_TEXTURE0</code>. In the fragment shader, we will use a special uniform of type <code>sampler2D</code> named <code>texSampler</code>. This uniform will sample a texel at the given texture coordinate. In order for the sampler to know which texture it should sample, this uniform should be initialized with the texture unit the texture is bound to.</p>
          <button type="button" class="btn btn-info" data-toggle="collapse" data-target="#use_texture_in_sp"> C++ code to use a texture in the shader program</button>
          <div id="use_texture_in_sp" class="collapse">
            <pre><code class="cpp">// Send positions, normals, ...  as usual
...

// Get ids from the shader program
int texcoordLocation = m_shaderProgram->getAttributeLocation("vTexCoord");
int texsamplerLocation = m_shaderProgram->getUniformLocation("texSampler");

// Bind texture on the texture unit 0
glActiveTexture(GL_TEXTURE0);
glBindTexture(GL_TEXTURE_2D, m_texId);

// Tells the sampler to use the texture unit 0
glUniform1i(texsamplerLocation, 0);

// Populate the vertex attribute with the texture coordinates buffer
glEnableVertexAttribArray(texcoordLocation);
glBindBuffer(GL_ARRAY_BUFFER, m_tBuffer);
glVertexAttribPointer(texcoordLocation, 2, GL_FLOAT, GL_FALSE, 0, (void*)0);

// Once you're done, release the texture
glBindTexture(GL_TEXTURE_2D, 0);</code></pre>
          </div>

          <h3> 3.2 GPU code for texturing </h3>
          <h4> Vertex shader </h4>
          <p> In the vertex shader, there is not much to do. You just have to transmit the texture coordinates to the fragment buffer in order to have interpolated texture coordinates for each fragment. </p>
          <button type="button" class="btn btn-info" data-toggle="collapse" data-target="#vertex_shader"> GLSL vertex shader</button>
          <div id="vertex_shader" class="collapse">
            <pre><code class="glsl">#version 400
uniform mat4 projMat, viewMat, modelMat;

in vec3 vPosition;
in vec2 vTexCoord;
out vec2 surfel_texCoord;

void main()
{
    gl_Position = projMat*viewMat*modelMat*vec4(vPosition, 1.0f);
    // simply pass the texture coordinate to the fragment
    surfel_texCoord = vTexCoord;
}</code></pre>
          </div>

          <h4> Fragment shader </h4>
          <p> The fragment is more interesting since this is the place where a texel is fetched and used to compute the color of a fragment. The sampling of the texture at the given texture coordinate is done by the sampler (a <code> sampler2D</code> in our case as the texture is two-dimensional). This operation is performed by applying the function <code>texture()</code> with the sampler and the texture coordinate.</p>
          <button type="button" class="btn btn-info" data-toggle="collapse" data-target="#fragment_shader"> GLSL fragment shader</button>
          <div id="fragment_shader" class="collapse">
            <pre><code class="glsl">#version 400
uniform sampler2D texSampler;

in vec2 surfel_texCoord;
out vec4 outColor;

void main()
{
    // here, the color is simply the texel
    outColor = texture(texSampler, surfel_texCoord);
}</code></pre>
          </div>

          <p>In the above example, the final color of a fragment is the sampled texel. We can use the texel in other ways. For example, it can be combined with the local illumination color of a surfel (as done in the previous practical).</p>
          <button type="button" class="btn btn-info" data-toggle="collapse" data-target="#fragment_shader2"> GLSL fragment shader with local illumination </button>
          <div id="fragment_shader2" class="collapse">
            <pre><code class="glsl">#version 400
...

void main()
{
    // compute the Phong color based on material and lights
    illuminationColor = ...

    // get the texel
    textureColor = texture(texSampler, surfel_texCoord);

    // combine the two, using custom operations (here a simple *) or the GLSL funtion `mix`
    outColor = textureColor * vec4(illuminationColor, 1.0);
}</code></pre>
          </div>

          <h2 id="bunny_uv_map">Exercise 1: Textured bunny </h2>
          <p> Look at the files <samp>texturing/TexturedLightedMeshRenderable.[cpp|hpp]</samp>. Texturing was added to the mesh class of previous practical. Identify the different steps of texturing, presented in the above section.</p>
          
          <h2 id="exo2"> Exercise 2: Wrapping options</h2>
          <p>
            First, let's focus on the ground plane of the scene. A grass texture is directly mapped on it: the coordinates textures of each corner are respectively \((0,0)\), \((1,0)\), \((1,1)\) and \((0,1)\). 
          </p>
          <p>
          	Ok, the plane looks like your garden. But what happens if you zoom on it? You should clearly see the (square) pixels of the image, which is not really nice. Actually this is due to the image resolution (here <samp>512x512</samp> pixels): it looks good only if mapped on a not too large plane, or if the camera is far enough. One could use a larger image, which would however consumes more ressouces. The usual solution is to use <b>texture tiling</b>, which means an image will be <i>repeated</i> to fully cover the polygon to texture, while limiting its zooming factor.
          </p>
          <p> Several <i>wrapping</i> options could be defined, with the command <code>glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, ...);</code>.
            Press the <samp>F6</samp> key to change the wrapping options for the ground:
          </p>
          <ul>
            <li>
              the texture coordinates will not be in \([0,1]^2\) anymore, but in \([-5,5]^2\)
            </li>
            <li>
              the wrapping value will be <code>GL_CLAMP_TO_EDGE</code>then <code>GL_REPEAT</code>, <code>GL_MIRRORED_REPEAT</code> and <code>GL_CLAMP_TO_BORDER</code>.
            </li>
          </ul>

          <p>Questions:</p>
          <ul>
            <li>What is the behavior with these different values? </li>
            <li>What caracteristics must be fulfilled by the texture image?</li>
          </ul>

          <h2 id="exo3"> Exercise 3: Filtering options</h2>
          <p>
            The <samp>F7</samp> key is assigned to interactively toggle the texture <b>interpolation</b> mode between <code>GL_LINEAR</code> and <code>GL_NEAREST</code>, for the ground plane. This is again done with the <code>glTexParameteri</code> function (see how key events are handled in <samp>TexturedPlaneRenderable.cpp</samp>). 
            Observe and understand the differences. At what rendering stage is this filtering operation performed? 
          </p>

          <h2 id="exo4"> Exercise 4: Multi-resolution (mipmapping)</h2>
          <p>
            Texture resolution plays an important role in the quality of the scene rendering. However, with a higher resolution comes a higher price in terms of ressource consumption (storage) and bandwith (texture loading and access). 
            Also, a polygon rendered far away doesn't need to be rendered with high resolution. In fact, it would run into the aliasing problem linked to discrete sampling of the texture. 
          </p>
          <p>
            The <b>mipmapping</b> technique is a way to address these issues by using several pre-filtered resolution levels of the same texture image.
            Depending on the distance between each fragment and the camera, the rendering process will automatically switch to the most adequate resolution of the texture.
          </p>

          <p> The cube on the left (an instance of the <samp>TexturedCubeRenderable</samp> class) is textured without mipmapping. However, mipmapping is used for the cube in the middle (a <samp>MipMapCubeRenderable</samp>). 
          <!-- With mipmapping a single texture is created but from several images at different resolutions:</p> -->
          <ul>
            <li>
              Look at the <samp>MipMapCubeRenderable</samp> class: a single texture is created, however several images are loaded with different resolutions (here <samp>256x256</samp>, <samp>128x128</samp>, ...). You can observe these images directly with a standard viewer: <samp>eog textures/mipmap1.png</samp>. A different figure enables to clearly identify which image is currently used to render a fragment.
            </li>
            <li>
              Play with the camera to zoom in and out, and vizualize the scene with different angles. On the left cube, you should clearly observe the <i>aliasing</i> problem. On the middle one, notice how the rendered image is swapped from one view point to another.
            </li>
            <li>
              In mipmapping as well, several filtering options are available: <code>GL_NEAREST_MIPMAP_NEAREST</code>, <code>GL_LINEAR_MIPMAP_NEAREST</code>, <code>GL_NEAREST_MIPMAP_LINEAR</code> and <code>GL_LINEAR_MIPMAP_LINEAR</code>. 
              Toggle the <samp>F8</samp> key to test these filtering options. 
            </li>
            <li>
              Can you explain the differences?
              What parameter provides the best and smoothest rendering quality? At what cost?
            </li>
          </ul>

          <p>In a real application, you generally won't create several images at different resolutions. Instead, one should load the desired image then use the <code>glGenerateTextureMipmap</code> function once to generate the sub-resolutions images.
          </p>

          <h2 id="exo5"> Exercise 5: Multi-texturing </h2>
          
          <p> The cube on the right (of class <samp>MultiTexturedCubeRenderable</samp>) is textured with two textures. This means that:</p>
          <ul>
            <li>two textures are created and loaded</li>
            <li>two texture units are used </li>
            <li>a vertex has two texture coordinates attributes </li>
            <li>the fragment shader uses two sampler.</li>
          </ul>
          
          <p> In order to clearly see the two different textures, the rendering is animated: the final color of a fragment is a linear interpolation between the two texels. The coefficient for the linear interpolation is simply the sinus of the animation time (see the <code>blendingCoeff</code> in <samp>MultiTexturedCubeRenderable.cpp</samp> and <samp>multiTextureFragment.glsl</samp>). This example not only shows you how to use multitexturing, but also how to animate the rendering of your objects. </p>

          <p>You could also try different combinations of the illuminated and texture(s) colors, in the fragment shader. So far a multiplication is done. Could you add the colors, use one of them only or use their alpha channel? 
          Do it manually or document yourself about the GLSL <code>mix</code> function to combine colors.
          <p>

          
          <h2 id="exo6"> Exercice 6: Project related </h2>
          <p> Texturing is the last feature you will have seen in this practicals. You can now add texturing to the renderables in your project. For example, we recommend to texture your kart or your driver, or some surrounding objects. If you do not want to spend hours to build a texture and a set of texture coordinates, find repeating textures. Take a moment to fully understand how both concepts work.</p>

        </div>
        <div class="col-md-2 scrollspy" role="complementary" id="page-nav">
          <nav class="hidden-xs hidden-sm hidden-print" data-spy="affix">
            <ul class="nav">
              <li> <a href="#reminder"> 1. Reminder </a> </li>
              <li> <a href="#additional"> 2. Additional files </a> </li>
              <li> <a href="#provided_code"> 3. Provided code </a> </li>
              <li> <a href="#bunny_uv_map"> Exercice 1: Textured bunny </a> </li>
              <li> <a href="#exo2"> Exercice 2: Wrapping options </a> </li>
              <li> <a href="#exo3"> Exercice 3: Filtering options </a> </li>
              <li> <a href="#exo4"> Exercice 4: Mipmapping </a> </li>
              <li> <a href="#exo5"> Exercice 5: Multi-texturing </a> </li>
              <li> <a href="#exo6"> Exercice 6: Project related </a> </li>
              
              <li> <a href="../api_doc/index.html"> API's documentation </a> </li>
              <li> <a class="to-top" href="#top"><span class="glyphicon glyphicon-menu-up"></span>Back to top </a> </li>
            </ul>
          </nav>
        </div> <!-- end scrollspy sidebare-->
      </div> <!-- end of row -->
    </div> <!-- end of container -->
    <footer>
      <p>
        <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
          <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" />
        </a>
        <span property="dct:title"> CG3D practicals</span> by 
        <span property="cc:attributionName">Pierre-Luc Manteaux</span> and 
        <span property="cc:attributionName">Thomas Delame</span> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>
    </footer>
  </body>
